import csv
import time
import re
import os
import pandas as pd
from google import genai  # ìµœì‹  SDK ì‚¬ìš©
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. í™˜ê²½ ì„¤ì • ë° ì¹´í…Œê³ ë¦¬ --- (ê¸°ì¡´ ìœ ì§€)
CATEGORIES = {
   "ëª¨ë°”ì¼": "https://news.naver.com/breakingnews/section/105/731",
   "ì¸í„°ë„· & SNS": "https://news.naver.com/breakingnews/section/105/226",
   "í†µì‹  & ë‰´ë¯¸ë””ì–´": "https://news.naver.com/breakingnews/section/105/227",
   "IT ì¼ë°˜": "https://news.naver.com/breakingnews/section/105/230",
   "ì»´í“¨í„°": "https://news.naver.com/breakingnews/section/105/283",
   "ê³¼í•™ ì¼ë°˜": "https://news.naver.com/breakingnews/section/105/228"
}

client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

def setup_driver():
   options = Options()
   options.add_argument("--headless")
   options.add_argument("--no-sandbox")
   options.add_argument("--disable-dev-shm-usage")
   options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
   return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# --- 2. ìˆ˜ì§‘ ë° ì •ì œ ì—”ì§„ (ê¸°ì¡´ ìœ ì§€) ---
def clean_text(text):
   return re.sub(r'[^ê°€-í£\s]', '', text)

def collect_section_news(driver, category_name, url):
   print(f"ğŸ“‚ [{category_name}] ì„¹ì…˜ ìˆ˜ì§‘ ì‹œì‘...")
   driver.get(url)
   news_data, seen_links, found_yesterday = [], set(), False

   while not found_yesterday:
       articles = driver.find_elements(By.CLASS_NAME, "sa_item")
       if not articles: break

       for article in articles:
           try:
                dt_el = article.find_element(By.CSS_SELECTOR, ".sa_text_datetime b")
                time_text = dt_el.text.strip()
                if "1ì¼ì „" in time_text:
                    found_yesterday = True
                    break

                title_el = article.find_element(By.CLASS_NAME, "sa_text_title")
                title, link = title_el.text.strip(), title_el.get_attribute("href")

                if link not in seen_links:
                    news_data.append([category_name, title, time_text, link])
                    seen_links.add(link)
           except: continue

       if found_yesterday: break
       try:
           more_btn = driver.find_element(By.CLASS_NAME, "section_more_inner")
           more_btn.click()
           time.sleep(1.5)
       except: break
   return news_data

def filter_ai_keywords(data_list):
   pattern = re.compile(r'ai|ì¸ê³µì§€ëŠ¥', re.IGNORECASE)
   return [item for item in data_list if pattern.search(item[1])]

def deduplicate_articles(data_list, threshold=0.2):
   if not data_list: return []
   df = pd.DataFrame(data_list, columns=['ë¶„ë¥˜', 'ì œëª©', 'ì‹œê°„', 'ë§í¬'])
   final_indices = []
   for category in df['ë¶„ë¥˜'].unique():
       cat_df = df[df['ë¶„ë¥˜'] == category].copy()
       if len(cat_df) <= 1:
           final_indices.extend(cat_df.index.tolist()); continue
       titles = cat_df['ì œëª©'].apply(clean_text).tolist()
       matrix = TfidfVectorizer().fit_transform(titles)
       sim = cosine_similarity(matrix, matrix)
       keep = [True] * len(cat_df)
       for i in range(len(cat_df)):
           if not keep[i]: continue
           for j in range(i+1, len(cat_df)):
                if sim[i, j] > threshold: keep[j] = False
       final_indices.extend(cat_df.iloc[keep].index.tolist())
   return df.loc[final_indices].values.tolist()

# --- 3. Gemini 3 ì§€ëŠ¥í˜• ë¶„ì„ ì—”ì§„ (í”„ë¡¬í”„íŠ¸/ì„¤ì • ì ˆëŒ€ ë³´ì¡´) ---
def analyze_category_with_gemini(category_name, articles):
   if not articles:
       return f"### {category_name}\nìˆ˜ì§‘ëœ ì£¼ìš” AI ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

   article_list_str = "\n".join([f"- {a[1]} ({a[3]})" for a in articles])

   prompt = f"""
    ë‹¹ì‹ ì€ IT ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ '{category_name}' ë¶„ì•¼ì˜ ë‰´ìŠ¤ë“¤ì„ êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ í™•ì¸í•˜ê³  ì •ë…í•œ ë’¤ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    [ë¶„ì„ ì œì™¸] AI ë¹„í•µì‹¬ ê¸°ì‚¬, ë‹¨ìˆœ ì£¼ê°€/ì‹œì´ ë‰´ìŠ¤, ì •ë³´ ì—†ëŠ” ì¼ë°˜ ì¸ì‚¬ì´íŠ¸ ê¸°ì‚¬.
    [ì‘ì„± ê·œì¹™]
    1. ê°€ì¥ ë§ì´ ì–¸ê¸‰ë˜ëŠ” í•µì‹¬ ì´ìŠˆ ìš”ì•½: í˜„ì¬ í•´ë‹¹ ë¶„ì•¼ì˜ ê°€ì¥ í° íë¦„ì„ 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³  ê´€ë ¨ ë§í¬ë¥¼ ì œê³µ
    2. ì‹ ì œí’ˆ/ì‹ ê¸°ëŠ¥ ì†Œì‹: AI ê´€ë ¨ ì‹ ì œí’ˆ, ì‹ ê¸°ëŠ¥, ì„œë¹„ìŠ¤ ì¶œì‹œ ë° ì˜ˆì • ì†Œì‹ì´ ìˆë‹¤ë©´ ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
    3.ì‚¬íšŒ/ì œë„/ì‹œì¥ì˜ ë³€í™”: AIë¡œ ì¸í•œ ê¸°ì¡´ ì‹œìŠ¤í…œì´ë‚˜ ì‹œì¥ êµ¬ì¡°ì˜ êµ¬ì²´ì ì¸ 'ë³€í™”' ë‚´ìš©ì„ ìš”ì•½
    4. **[í•„ìˆ˜] ì „ë¬¸ ìš©ì–´ëŠ” ê´„í˜¸ë¥¼ ì‚¬ìš©í•´ ì¹œì ˆí•˜ê²Œ í’€ì–´ì„œ ì„¤ëª…í•  ê²ƒ.**

    ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸:
    {article_list_str}
   """

   try:
       print(f"ğŸ¤– Gemini 3 ë¶„ì„ ì¤‘: {category_name}")
       response = client.models.generate_content(
           model='gemini-3-flash-preview', 
           contents=prompt,
           config={'tools': [{'google_search': {}}]}
       )
       # ê²°ê³¼ ë°˜í™˜ ì‹œ Markdown ë¬¸ë²• ìœ ì§€
       return f"## ğŸ“Œ {category_name} ë™í–¥ ë¶„ì„\n{response.text}\n\n"
   except Exception as e:
       return f"## ğŸ“Œ {category_name} ë¶„ì„ ì—ëŸ¬: {e}\n"

# --- 4. ì›¹ ë³€í™˜ í—¬í¼ (ìƒˆë¡œ ì¶”ê°€) ---
def save_as_html(content_list):
    """ë³´ê³ ì„œ ë‚´ìš©ì„ HTML ì›¹ì‚¬ì´íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    import markdown
    full_markdown = "".join(content_list)
    html_content = markdown.markdown(full_markdown, extensions=['fenced_code', 'tables'])
    
    html_template = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Daily AI Report</title>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.2.0/github-markdown.min.css">
        <style>
            body {{ box-sizing: border-box; min-width: 200px; max-width: 980px; margin: 0 auto; padding: 45px; }}
            @media (max-width: 767px) {{ .markdown-body {{ padding: 15px; }} }}
        </style>
    </head>
    <body class="markdown-body">
        {html_content}
        <hr>
        <p style="text-align:center; color:gray;">Last Updated: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
    </body>
    </html>
    """
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_template)

# --- 5. ë©”ì¸ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ (ìˆ˜ì •ë¨) ---
if __name__ == "__main__":
   driver = setup_driver()
   raw_news = []

   try:
       for cat, url in CATEGORIES.items():
           raw_news.extend(collect_section_news(driver, cat, url))
       
       print(f"\n--- 1ë‹¨ê³„: ìˆ˜ì§‘ ì™„ë£Œ ({len(raw_news)}ê±´) ---")

       ai_news = filter_ai_keywords(raw_news)
       final_list = deduplicate_articles(ai_news, threshold=0.2)
       print(f"âœ¨ í•„í„°ë§ ê²°ê³¼: ìˆ˜ì§‘({len(raw_news)}) -> AIì¶”ì¶œ({len(ai_news)}) -> ì¤‘ë³µì œê±°({len(final_list)})")

       report_content = ["# ğŸ¤– ì˜¤ëŠ˜ì˜ AI ê¸°ìˆ  ë° ì‹œì¥ ë™í–¥ ë³´ê³ ì„œ\n\n"]
       df_final = pd.DataFrame(final_list, columns=['ë¶„ë¥˜', 'ì œëª©', 'ì‹œê°„', 'ë§í¬'])
       
       for category in CATEGORIES.keys():
           category_articles = df_final[df_final['ë¶„ë¥˜'] == category].values.tolist()
           report_content.append(analyze_category_with_gemini(category, category_articles))
       
       # ê¸°ì¡´ íŒŒì¼ ì €ì¥ ìœ ì§€
       with open("AI_Daily_Report.md", "w", encoding="utf-8") as f:
           f.writelines(report_content)
       
       # ì›¹ì‚¬ì´íŠ¸ íŒŒì¼(index.html) ìƒì„± ë¡œì§ ì¶”ê°€
       save_as_html(report_content)
       
       pd.DataFrame(final_list, columns=['ë¶„ë¥˜','ì œëª©','ì‹œê°„','ë§í¬']).to_csv("naver_today_news.csv", index=False, encoding='utf-8-sig')
       
       print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ: index.html ìƒì„±ë¨")

   finally:
       driver.quit()
