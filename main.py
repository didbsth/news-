import csv
import time
import re
import os
import pandas as pd
from google import genai  # ìµœì‹  SDK ì‚¬ìš©
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# --- 1. í™˜ê²½ ì„¤ì • ë° ì¹´í…Œê³ ë¦¬ ---
CATEGORIES = {
    "ëª¨ë°”ì¼": "https://news.naver.com/breakingnews/section/105/731",
    "ì¸í„°ë„· & SNS": "https://news.naver.com/breakingnews/section/105/226",
    "í†µì‹  & ë‰´ë¯¸ë””ì–´": "https://news.naver.com/breakingnews/section/105/227",
    "IT ì¼ë°˜": "https://news.naver.com/breakingnews/section/105/230",
    "ì»´í“¨í„°": "https://news.naver.com/breakingnews/section/105/283",
    "ê³¼í•™ ì¼ë°˜": "https://news.naver.com/breakingnews/section/105/228"
}

# 2026ë…„ ìµœì‹  Gemini 3 ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = genai.Client(api_key=os.environ.get("GEMINI_API_KEY"))

def setup_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# --- 2. ìˆ˜ì§‘ ë° ì •ì œ ì—”ì§„ (ì²« ë²ˆì§¸ ì½”ë“œ ë¡œì§) ---

def clean_text(text):
    return re.sub(r'[^ê°€-í£\s]', '', text)

def collect_section_news(driver, category_name, url):
    print(f"ğŸ“‚ [{category_name}] ì„¹ì…˜ ìˆ˜ì§‘ ì‹œì‘...")
    driver.get(url)
    news_data, seen_links, found_yesterday = [], set(), False

    while not found_yesterday:
        articles = driver.find_elements(By.CLASS_NAME, "sa_item")
        if not articles: break

        for article in articles:
            try:
                dt_el = article.find_element(By.CSS_SELECTOR, ".sa_text_datetime b")
                time_text = dt_el.text.strip()
                if "1ì¼ì „" in time_text:
                    found_yesterday = True
                    break

                title_el = article.find_element(By.CLASS_NAME, "sa_text_title")
                title, link = title_el.text.strip(), title_el.get_attribute("href")

                if link not in seen_links:
                    news_data.append([category_name, title, time_text, link])
                    seen_links.add(link)
            except: continue

        if found_yesterday: break
        try:
            more_btn = driver.find_element(By.CLASS_NAME, "section_more_inner")
            more_btn.click()
            time.sleep(1.5)
        except: break
    return news_data

def filter_ai_keywords(data_list):
    pattern = re.compile(r'ai|ì¸ê³µì§€ëŠ¥', re.IGNORECASE)
    return [item for item in data_list if pattern.search(item[1])]

def deduplicate_articles(data_list, threshold=0.2):
    if not data_list: return []
    df = pd.DataFrame(data_list, columns=['ë¶„ë¥˜', 'ì œëª©', 'ì‹œê°„', 'ë§í¬'])
    final_indices = []
    for category in df['ë¶„ë¥˜'].unique():
        cat_df = df[df['ë¶„ë¥˜'] == category].copy()
        if len(cat_df) <= 1:
            final_indices.extend(cat_df.index.tolist()); continue
        titles = cat_df['ì œëª©'].apply(clean_text).tolist()
        matrix = TfidfVectorizer().fit_transform(titles)
        sim = cosine_similarity(matrix, matrix)
        keep = [True] * len(cat_df)
        for i in range(len(cat_df)):
            if not keep[i]: continue
            for j in range(i+1, len(cat_df)):
                if sim[i, j] > threshold: keep[j] = False
        final_indices.extend(cat_df.iloc[keep].index.tolist())
    return df.loc[final_indices].values.tolist()

# --- 3. Gemini 3 ì§€ëŠ¥í˜• ë¶„ì„ ì—”ì§„ (ë‘ ë²ˆì§¸ ì½”ë“œ ë¡œì§) ---

def analyze_category_with_gemini(category_name, articles):
    if not articles:
        return f"### {category_name}\nìˆ˜ì§‘ëœ ì£¼ìš” AI ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n"

    # ìƒìœ„ 10ê°œ ê¸°ì‚¬ë¥¼ ìš”ì•½ ëŒ€ìƒìœ¼ë¡œ ì „ë‹¬
    article_list_str = "\n".join([f"- {a[1]} ({a[3]})" for a in articles])

    prompt = f"""
    ë‹¹ì‹ ì€ IT ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ '{category_name}' ë¶„ì•¼ì˜ ë‰´ìŠ¤ë“¤ì„ êµ¬ê¸€ ê²€ìƒ‰ìœ¼ë¡œ í™•ì¸í•˜ê³  ì •ë…í•œ ë’¤ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

    [ë¶„ì„ ì œì™¸] AI ë¹„í•µì‹¬ ê¸°ì‚¬, ë‹¨ìˆœ ì£¼ê°€/ì‹œì´ ë‰´ìŠ¤, ì •ë³´ ì—†ëŠ” ì¼ë°˜ ì¸ì‚¬ì´íŠ¸ ê¸°ì‚¬.
    [ì‘ì„± ê·œì¹™]
    1. ê°€ì¥ ë§ì´ ì–¸ê¸‰ë˜ëŠ” í•µì‹¬ ì´ìŠˆ ìš”ì•½: í˜„ì¬ í•´ë‹¹ ë¶„ì•¼ì˜ ê°€ì¥ í° íë¦„ì„ 2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³  ê´€ë ¨ ë§í¬ë¥¼ ì œê³µ
    2. ì‹ ì œí’ˆ/ì‹ ê¸°ëŠ¥ ì†Œì‹: AI ê´€ë ¨ ì‹ ì œí’ˆ, ì‹ ê¸°ëŠ¥, ì„œë¹„ìŠ¤ ì¶œì‹œ ë° ì˜ˆì • ì†Œì‹ì´ ìˆë‹¤ë©´ ìµœëŒ€ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
    3.ì‚¬íšŒ/ì œë„/ì‹œì¥ì˜ ë³€í™”: AIë¡œ ì¸í•œ ê¸°ì¡´ ì‹œìŠ¤í…œì´ë‚˜ ì‹œì¥ êµ¬ì¡°ì˜ êµ¬ì²´ì ì¸ 'ë³€í™”' ë‚´ìš©ì„ ìš”ì•½
    4. **[í•„ìˆ˜] ì „ë¬¸ ìš©ì–´ëŠ” ê´„í˜¸ë¥¼ ì‚¬ìš©í•´ ì¹œì ˆí•˜ê²Œ í’€ì–´ì„œ ì„¤ëª…í•  ê²ƒ.**

    ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸:
    {article_list_str}
    """

    try:
        print(f"ğŸ¤– Gemini 3 ë¶„ì„ ì¤‘: {category_name}")
        # ìµœì‹  SDK ë°©ì‹ì˜ Google Search í˜¸ì¶œ
        response = client.models.generate_content(
            model='gemini-3-flash-preview', # í˜¹ì€ 'gemini-flash-latest'
            contents=prompt,
            config={'tools': [{'google_search': {}}]}
        )
        return f"## ğŸ“Œ {category_name} ë™í–¥ ë¶„ì„\n{response.text}\n\n"
    except Exception as e:
        return f"## ğŸ“Œ {category_name} ë¶„ì„ ì—ëŸ¬: {e}\n"

# --- 4. ë©”ì¸ ì‹¤í–‰ í”„ë¡œì„¸ìŠ¤ ---

if __name__ == "__main__":
    driver = setup_driver()
    raw_news = []

    try:
        # ë‹¨ê³„ 1: ì‹¤ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰ (ì¤‘ìš”)
        for cat, url in CATEGORIES.items():
            raw_news.extend(collect_section_news(driver, cat, url))
        
        print(f"\n--- 1ë‹¨ê³„: ìˆ˜ì§‘ ì™„ë£Œ ({len(raw_news)}ê±´) ---")

        # ë‹¨ê³„ 2: AI í•„í„°ë§ ë° ì¤‘ë³µ ì œê±°
        ai_news = filter_ai_keywords(raw_news)
        final_list = deduplicate_articles(ai_news, threshold=0.2)
        print(f"âœ¨ í•„í„°ë§ ê²°ê³¼: ìˆ˜ì§‘({len(raw_news)}) -> AIì¶”ì¶œ({len(ai_news)}) -> ì¤‘ë³µì œê±°({len(final_list)})")

        # ë‹¨ê³„ 3: ë¶„ë¥˜ë³„ ê·¸ë£¹í™” ë° Gemini ë¶„ì„
        report_content = ["# ğŸ¤– ì˜¤ëŠ˜ì˜ AI ê¸°ìˆ  ë° ì‹œì¥ ë™í–¥ ë³´ê³ ì„œ\n\n"]
        df_final = pd.DataFrame(final_list, columns=['ë¶„ë¥˜', 'ì œëª©', 'ì‹œê°„', 'ë§í¬'])
        
        for category in CATEGORIES.keys():
            category_articles = df_final[df_final['ë¶„ë¥˜'] == category].values.tolist()
            report_content.append(analyze_category_with_gemini(category, category_articles))
        
        # ë‹¨ê³„ 4: ê²°ê³¼ ì €ì¥
        with open("AI_Daily_Report.md", "w", encoding="utf-8") as f:
            f.writelines(report_content)
        pd.DataFrame(final_list, columns=['ë¶„ë¥˜','ì œëª©','ì‹œê°„','ë§í¬']).to_csv("naver_today_news.csv", index=False, encoding='utf-8-sig')
        
        print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ: AI_Daily_Report.md ë° naver_today_news.csv ìƒì„±ë¨")

    finally:
        driver.quit()
